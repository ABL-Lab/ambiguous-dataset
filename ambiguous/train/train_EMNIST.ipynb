{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "import ambiguous.models.cvae\n",
    "from ambiguous.models.cvae import *\n",
    "from ambiguous.dataset.dataset import partition_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the working directory from timestamp and model name\n",
    "model_name = 'cvae_emnist' # invertible network\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "workingDir = f'tb_logs/{model_name}_{timestamp}'\n",
    "os.mkdir(workingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "latent_dim = 4\n",
    "TRAIN_CVAE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])#,  transforms.Resize((32,32))]) # Dataset transform #  lambda x: (x>0.5).float(),\n",
    "dataset = datasets.EMNIST(root='/share/datasets', download=False, split='byclass', train=True, transform=transform)\n",
    "dataset = partition_dataset(dataset, range(10, 36))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [round(0.8*len(dataset)), round(0.2*len(dataset))])\n",
    "test_set = datasets.EMNIST(root='/share/datasets', download=False, split='byclass', train=False, transform=transform)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=12, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=12, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,t=next(iter(train_loader))\n",
    "torchvision.utils.save_image(next(iter(train_loader))[0], 'image.pdf', nrow=8)\n",
    "print(['abcdefghijklmnopqrstuvwxyz'[i] for i in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=./tb_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardLogger('tb_logs', name=model_name)\n",
    "enc_layers = [28*28, 1024, 1024]\n",
    "dec_layers = [1024, 1024, 28*28]\n",
    "if TRAIN_CVAE:\n",
    "    model = EMNIST_CVAE(latent_dim, enc_layers, dec_layers, n_classes=26, conditional=True).to(device)\n",
    "    trainer = pl.Trainer(gpus=1,logger=tb_logger,max_epochs=100,auto_lr_find=True)\n",
    "    trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56b94a22e0b30145bc461d50c8481827ccfe484109677afaff2bcdc486ba3cbc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dev-2021-02-py38': venv)",
   "language": "python",
   "name": "python38564bitdev202102py38venved5311bfb7744d6caaf9ece0ad44c9d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "56b94a22e0b30145bc461d50c8481827ccfe484109677afaff2bcdc486ba3cbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
