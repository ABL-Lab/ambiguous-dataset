{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63643a64-d789-4ffb-8798-e0f7b5657b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nislah/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import *\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "from project.data_utils import *\n",
    "from project.models.ambiguous_generator import *\n",
    "from project.models.cvae import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f795aa2-8c09-4f57-a3d0-6293a16556fb",
   "metadata": {},
   "source": [
    "# EMNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac59921-7a2e-4b5a-b3cd-0dce611c6dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('dataset/emnist_params.yaml','r') as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "n_classes = 26\n",
    "latent_dim = 4\n",
    "enc_layers = [28*28, 512]\n",
    "dec_layers = [512, 28*28]\n",
    "ckpt_path = params['ckpt_path']\n",
    "img_path = params['img_path']\n",
    "model = EMNIST_CVAE(latent_dim, enc_layers, dec_layers, n_classes=26, conditional=True).to(device)\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.eval()\n",
    "encoder,decoder = model.encoder,model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4efcd1-b5dd-4645-bbc8-21a28ace0f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = datasets.EMNIST(root='/share/datasets', download=False, train=True, split='letters', transform=transforms.Compose([transforms.ToTensor()]))\n",
    "generator = EMNISTGenerator(encoder, decoder, DataLoader(dataset, batch_size=2, shuffle=True), n_classes=n_classes, device=device)\n",
    "letters='abcdefghijklmnopqrstuvwxyz'\n",
    "idx = lambda x: letters.index(x)\n",
    "pure_pairs = np.array([(idx('c'), idx('o')), (idx('c'), idx('e'))])\n",
    "dataset = AmbiguousDataset(generator, pure_pairs, blend=0.5, n_classes=n_classes)\n",
    "ambiguousDataLoader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "x,t = next(iter(ambiguousDataLoader))\n",
    "save_image(x,img_path,nrow=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a0dba-b80f-4f87-979d-64096098eaf2",
   "metadata": {},
   "source": [
    "# MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cdb2d42-e9e3-4183-a362-0fecea541a72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Encoder(\n",
       "   (l1): Linear(in_features=794, out_features=500, bias=True)\n",
       "   (l2): Linear(in_features=500, out_features=4, bias=True)\n",
       " ),\n",
       " Decoder(\n",
       "   (l1): Linear(in_features=12, out_features=500, bias=True)\n",
       "   (l2): Linear(in_features=500, out_features=784, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset/save_dict.yaml','r') as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "n_classes = params['n_classes']\n",
    "img_path=params['img']\n",
    "pure_pairs=np.array([(3,8),(8,3),(3,5),(5,3),(5,8),(8,5),(0,6),(6,0)])\n",
    "encoder = torch.load(params['enc']).to(device)\n",
    "decoder = torch.load(params['dec']).to(device)\n",
    "encoder.eval(),decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d8319c-b015-4aa8-8e13-c05818d739bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root='/share/datasets', download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "generator = MNISTGenerator(encoder, decoder, DataLoader(dataset, batch_size=2, shuffle=True), n_classes=n_classes, device=device)\n",
    "dataset = AmbiguousDataset(generator, pure_pairs, transform=transforms.Compose([transforms.Resize((32,32))]), n_classes=n_classes, blend=0.5)\n",
    "ambiguousDataLoader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "x,t = next(iter(ambiguousDataLoader))\n",
    "save_image(x,img_path,nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fea32-dd33-4175-a73a-e662c27c6a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dev-2021-02-py38': venv)",
   "language": "python",
   "name": "python38564bitdev202102py38venved5311bfb7744d6caaf9ece0ad44c9d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
