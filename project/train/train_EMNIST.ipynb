{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nislah/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchvision\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "from project.models.cvae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  train_EMNIST_cvae.py  train_template.py\n",
      "tb_logs      train_EMNIST.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the working directory from timestamp and model name\n",
    "model_name = 'cvae_emnist' # invertible network\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "workingDir = f'tb_logs/{model_name}_{timestamp}'\n",
    "os.mkdir(workingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create configuration file\n",
    "configDict = {\n",
    "'workingDir': workingDir,\n",
    "'timestamp' : timestamp,\n",
    "#'dataset': 'MNIST', # Define working dataset\n",
    "'model': model_name, # Model\n",
    "'lr': 1e-3, # Learning rate\n",
    "'batch_size': 64,\n",
    "'n_epochs': 50,\n",
    "'kernel_size': 4, # kernel size\n",
    "\"init_channels\": 8, # initial number of filters\n",
    "\"image_channels\": 1, # 1 for MNIST (grayscale)\n",
    "\"latent_dim\": 4 # latent dimension for sampling\n",
    "}\n",
    "\n",
    "with open(f'{workingDir}/config.yaml', 'w') as file:\n",
    "    documents = yaml.dump(configDict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'image_channels': 1,\n",
       " 'init_channels': 8,\n",
       " 'kernel_size': 4,\n",
       " 'latent_dim': 4,\n",
       " 'lr': 0.001,\n",
       " 'model': 'cvae_emnist',\n",
       " 'n_epochs': 50,\n",
       " 'timestamp': '20220118_124928',\n",
       " 'workingDir': 'tb_logs/cvae_emnist_20220118_124928'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load configuration file\n",
    "with open(f'{workingDir}/config.yaml','r') as file:\n",
    "    params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import parameters and construct model and optimizers\n",
    "lr=params['lr']\n",
    "batch_size=params['batch_size']\n",
    "n_epochs=params['n_epochs']\n",
    "kernel_size=params['kernel_size'] # kernel size\n",
    "init_channels=params['init_channels'] # initial number of filters\n",
    "image_channels=params['image_channels'] # 1 for MNIST (grayscale)\n",
    "latent_dim=params['latent_dim'] # latent dimension for sampling\n",
    "TRAIN_CVAE = True\n",
    "TRAIN_VAE = False\n",
    "PLOT_VAE = False\n",
    "TRAIN_READOUT = False\n",
    "TRAIN_READIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define datasets\n",
    "# Prepare the data loader for the MNIST dataset:\n",
    "transform = transforms.Compose([transforms.ToTensor()])#,  transforms.Resize((32,32))]) # Dataset transform #  lambda x: (x>0.5).float(),\n",
    "dataset = datasets.EMNIST(root='/share/datasets', download=False, split='letters', train=True, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [100000, 24800])\n",
    "test_set = datasets.EMNIST(root='/share/datasets', download=False, split='letters', train=False, transform=transform)\n",
    "# dataset = datasets.MNIST(root='/share/datasets', download=False, train=True, transform=transform)\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=12, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=12, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(next(iter(train_loader))[0][0].permute(1,2,0))\n",
    "x,t=next(iter(train_loader))\n",
    "x0,t0=x[0],t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=./tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type           | Params\n",
      "-------------------------------------------\n",
      "0 | encoder | EMNIST_Encoder | 419 K \n",
      "1 | decoder | EMNIST_Decoder | 418 K \n",
      "-------------------------------------------\n",
      "837 K     Trainable params\n",
      "0         Non-trainable params\n",
      "837 K     Total params\n",
      "3.350     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST_CVAE(\n",
      "  (encoder): EMNIST_Encoder(\n",
      "    (MLP): Sequential(\n",
      "      (L0): Linear(in_features=810, out_features=512, bias=True)\n",
      "      (A0): ReLU()\n",
      "    )\n",
      "    (fc_mu): Linear(in_features=512, out_features=4, bias=True)\n",
      "    (fc_logvar): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      "  (decoder): EMNIST_Decoder(\n",
      "    (MLP): Sequential(\n",
      "      (L0): Linear(in_features=30, out_features=512, bias=True)\n",
      "      (A0): ReLU()\n",
      "      (L1): Linear(in_features=512, out_features=784, bias=True)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Epoch 0:  80%|████████████████████████████████████████████████▊            | 1563/1951 [00:07<00:01, 206.06it/s, loss=194, v_num=2]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                          | 0/388 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|█████████████████████████████████████████████████            | 1569/1951 [00:08<00:01, 194.85it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████████████████████████████████▊          | 1624/1951 [00:08<00:01, 199.19it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0:  86%|████████████████████████████████████████████████████▌        | 1681/1951 [00:08<00:01, 203.67it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0:  89%|██████████████████████████████████████████████████████▎      | 1738/1951 [00:08<00:01, 208.00it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0:  92%|████████████████████████████████████████████████████████     | 1795/1951 [00:08<00:00, 212.20it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0:  95%|█████████████████████████████████████████████████████████▉   | 1853/1951 [00:08<00:00, 216.47it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████| 1951/1951 [00:19<00:00, 102.14it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████| 1951/1951 [00:22<00:00, 87.88it/s, loss=194, v_num=2]\u001b[A\n",
      "Epoch 1:  36%|██████████████████████▏                                       | 698/1951 [00:04<00:07, 172.52it/s, loss=189, v_num=2]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nislah/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:895: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|██████████████████████▌                                        | 698/1951 [00:16<00:30, 41.35it/s, loss=189, v_num=2]"
     ]
    }
   ],
   "source": [
    "tb_logger = TensorBoardLogger('tb_logs', name=model_name)\n",
    "enc_layers = [28*28, 512]\n",
    "dec_layers = [512, 28*28]\n",
    "model = EMNIST_CVAE(latent_dim, enc_layers, dec_layers, n_classes=26, conditional=True).to(device)\n",
    "print(model)\n",
    "trainer = pl.Trainer(\n",
    "                     gpus=1,\n",
    "                     logger=tb_logger,\n",
    "                     max_epochs=100,\n",
    "#                      callbacks=[\n",
    "#                          pl.callbacks.early_stopping.EarlyStopping(\n",
    "#                              monitor='Val/Loss',\n",
    "#                              mode='min',\n",
    "#                              patience=5\n",
    "#                          )\n",
    "#                      ],\n",
    "                    auto_lr_find=True)\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56b94a22e0b30145bc461d50c8481827ccfe484109677afaff2bcdc486ba3cbc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dev-2021-02-py38': venv)",
   "language": "python",
   "name": "python38564bitdev202102py38venved5311bfb7744d6caaf9ece0ad44c9d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "56b94a22e0b30145bc461d50c8481827ccfe484109677afaff2bcdc486ba3cbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
